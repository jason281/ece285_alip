{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:05:02.523511Z",
     "start_time": "2018-12-09T21:05:01.704430Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:05:02.533700Z",
     "start_time": "2018-12-09T21:05:02.528637Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/data5/drone_machinelearning/amir/pix3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:02:51.274647Z",
     "start_time": "2018-12-02T09:02:51.266954Z"
    }
   },
   "outputs": [],
   "source": [
    "data='img'\n",
    "og_path = root + '/' + data\n",
    "train_path = og_path + '_split/train'\n",
    "test_path = og_path + '_split/test'\n",
    "classes = os.listdir(og_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:33:03.164412Z",
     "start_time": "2018-12-02T02:32:59.668717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:03<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(classes):\n",
    "    objs = sorted(os.listdir(og_path +'/' + c))\n",
    "    for i,obj in enumerate(objs):\n",
    "        if obj.split('.')[1] != 'png':\n",
    "            os.remove(og_path+'/'+c+'/'+obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T02:33:04.991405Z",
     "start_time": "2018-12-02T02:33:04.823299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 63.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(classes):\n",
    "    objs = sorted(os.listdir(og_path +'/' + c))\n",
    "    n = len(objs)\n",
    "    if not os.path.exists(train_path+'/'+c):\n",
    "        os.makedirs(train_path+'/'+c)\n",
    "    if not os.path.exists(test_path+'/'+c):\n",
    "        os.makedirs(test_path+'/'+c)\n",
    "    \n",
    "    for i,obj in enumerate(objs):\n",
    "        if obj.split('.')[1] == 'png':\n",
    "            if i<0.8*n:\n",
    "                img_src = og_path+'/'+c+'/'+obj\n",
    "                img_dst = train_path+'/'+c+'/'+obj\n",
    "                os.symlink(img_src, img_dst)\n",
    "            else:\n",
    "                img_src = og_path+'/'+c+'/'+obj\n",
    "                img_dst = test_path+'/'+c+'/'+obj\n",
    "                os.symlink(img_src, img_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:05:04.516472Z",
     "start_time": "2018-12-09T21:05:04.481690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('table', 1496, 1496, 1496, 1496, True)\n",
      "('chair', 3072, 3072, 3072, 3072, True)\n",
      "('wardrobe', 195, 195, 195, 195, True)\n",
      "('misc', 55, 55, 55, 55, True)\n",
      "('bed', 795, 795, 795, 795, True)\n",
      "('bookcase', 289, 289, 289, 289, True)\n",
      "('tool', 38, 38, 38, 38, True)\n",
      "('desk', 560, 560, 560, 560, True)\n",
      "('sofa', 1558, 1558, 1558, 1558, True)\n"
     ]
    }
   ],
   "source": [
    "render_path = root + '/render_split/train'\n",
    "foreground_path = root + '/foreground_split/train'\n",
    "background_path = root + '/background_split/train'\n",
    "img_path = root + '/img_split/train'\n",
    "\n",
    "for c in os.listdir(render_path):\n",
    "    l1 = len(os.listdir(render_path + '/' + c))\n",
    "    l2 = len(os.listdir(foreground_path + '/' + c))\n",
    "    l3 = len(os.listdir(img_path + '/' + c))\n",
    "    l4 = len(os.listdir(background_path + '/' + c))\n",
    "    print(c,l1,l2,l3,l4,l1==l2==l3==l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:05:17.835085Z",
     "start_time": "2018-12-09T21:05:17.806054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('table', 374, 374, 374, 374, True)\n",
      "('chair', 767, 767, 767, 767, True)\n",
      "('wardrobe', 48, 48, 48, 48, True)\n",
      "('misc', 13, 13, 13, 13, True)\n",
      "('bed', 198, 198, 198, 198, True)\n",
      "('bookcase', 72, 72, 72, 72, True)\n",
      "('tool', 9, 9, 9, 9, True)\n",
      "('desk', 140, 140, 140, 140, True)\n",
      "('sofa', 389, 389, 389, 389, True)\n"
     ]
    }
   ],
   "source": [
    "render_path = root + '/render_split/test'\n",
    "foreground_path = root + '/foreground_split/test'\n",
    "background_path = root + '/background_split/test'\n",
    "img_path = root + '/img_split/test'\n",
    "\n",
    "for c in os.listdir(render_path):\n",
    "    l1 = len(os.listdir(render_path + '/' + c))\n",
    "    l2 = len(os.listdir(foreground_path + '/' + c))\n",
    "    l3 = len(os.listdir(img_path + '/' + c))\n",
    "    l4 = len(os.listdir(background_path + '/' + c))\n",
    "    print(c,l1,l2,l3,l4,l1==l2==l3==l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T01:15:31.225054Z",
     "start_time": "2018-12-02T01:15:29.525221Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "annotations = json.load(open('pix3d.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:54:20.306016Z",
     "start_time": "2018-12-02T03:54:13.288547Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:29:06.158911Z",
     "start_time": "2018-12-02T13:29:06.147748Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/data5/drone_machinelearning/amir/pix3d'\n",
    "og_path = root + '/render'\n",
    "train_path = og_path + '_split/train'\n",
    "train_target_path = root +'/foreground_split/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:29:06.432026Z",
     "start_time": "2018-12-02T13:29:06.426058Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = og_path + '_split/test'\n",
    "test_target_path = root +'/foreground_split/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:54:26.856183Z",
     "start_time": "2018-12-02T03:54:20.324132Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = {}, {}\n",
    "train_dataset['input'], train_dataset['target'], test_dataset['input'], test_dataset['target'] = [], [], [], []\n",
    "train_dataset['input'] = torchvision.datasets.ImageFolder(train_path)\n",
    "train_dataset['target'] = torchvision.datasets.ImageFolder(train_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:01:47.469588Z",
     "start_time": "2018-12-02T09:01:47.270010Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-099e2d82e5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'Image'"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "img = PIL.Image.open(og_path+'/'+classes[0]+'/'+os.listdir(og_path+'/'+classes[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:39:10.982483Z",
     "start_time": "2018-12-02T12:39:10.975181Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from Arch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:39:26.258926Z",
     "start_time": "2018-12-02T12:39:26.203141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLayerDiscriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (4): LeakyReLU(0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (7): LeakyReLU(0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (10): LeakyReLU(0.2, inplace)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLayerDiscriminator(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:39:38.209173Z",
     "start_time": "2018-12-02T12:39:38.192835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixelDiscriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): LeakyReLU(0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (4): LeakyReLU(0.2, inplace)\n",
       "    (5): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PixelDiscriminator(input_nc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:02:13.613518Z",
     "start_time": "2018-12-02T12:02:13.603156Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = Variable(torch.Tensor(2,1,256,256).fill_(0.1).cuda(),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:02:14.142489Z",
     "start_time": "2018-12-02T12:02:14.131685Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = N_D(temp)\n",
    "t2 = P_D(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:02:16.960560Z",
     "start_time": "2018-12-02T12:02:16.954932Z"
    }
   },
   "outputs": [],
   "source": [
    "patch = t1.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:02:17.315828Z",
     "start_time": "2018-12-02T12:02:17.307645Z"
    }
   },
   "outputs": [],
   "source": [
    "A=torch.rand(*patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:02:20.643252Z",
     "start_time": "2018-12-02T12:02:20.612593Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c973b3a93fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got Variable"
     ]
    }
   ],
   "source": [
    "A=Variable(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:29:10.415676Z",
     "start_time": "2018-12-02T13:29:10.387328Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "input_transform = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224,scale=(0.6,1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "target_transform = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224,scale=(0.6,1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:29:11.703593Z",
     "start_time": "2018-12-02T13:29:11.460010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 99.45it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 477.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from DRLoader import DRLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "temp = DRLoader(train_path, train_target_path, in_transform=input_transform['train'] \\\n",
    "                             ,target_transform=target_transform['train'])\n",
    "temp2 = DRLoader(test_path, test_target_path, in_transform=input_transform['test'] \\\n",
    "                             ,target_transform=target_transform['test'])\n",
    "data= DataLoader(temp,32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:29:31.908439Z",
     "start_time": "2018-12-02T13:29:31.898592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8058,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:20:42.593414Z",
     "start_time": "2018-12-02T13:15:50.040046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 53/252 [04:47<17:58,  5.42s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 4 in dimension 1 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f6af0111d340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/drone/.local/lib/python2.7/site-packages/tqdm/_tqdm.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/drone/newanaconda2/envs/dronev3/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/drone/newanaconda2/envs/dronev3/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/drone/newanaconda2/envs/dronev3/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/drone/newanaconda2/envs/dronev3/lib/python2.7/site-packages/torch/functional.pyc\u001b[0m in \u001b[0;36mstack\u001b[0;34m(sequence, dim, out)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 4 in dimension 1 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i,(x,y,z) in enumerate(tqdm(data)):\n",
    "    if int(x.shape[1])!=4:\n",
    "        print(z)\n",
    "        print('x',x)\n",
    "        break\n",
    "    if y.shape[1]!=3:\n",
    "        print(z)\n",
    "        print('y',y)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T13:13:48.179410Z",
     "start_time": "2018-12-02T13:13:48.150477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1029\n",
       " 1030\n",
       " 1031\n",
       " 1032\n",
       " 1033\n",
       " 1034\n",
       " 1035\n",
       " 1036\n",
       " 1037\n",
       " 1038\n",
       " 1039\n",
       " 1040\n",
       " 1041\n",
       " 1042\n",
       " 1043\n",
       " 1044\n",
       " 1045\n",
       " 1046\n",
       " 1047\n",
       " 1048\n",
       " 1049\n",
       " 1050\n",
       " 1051\n",
       " 1052\n",
       " 1053\n",
       " 1054\n",
       " 1055\n",
       " 1056\n",
       " 1057\n",
       " 1058\n",
       " 1059\n",
       " 1060\n",
       " 1061\n",
       " 1062\n",
       " 1063\n",
       " 1064\n",
       " 1065\n",
       " 1066\n",
       " 1067\n",
       " 1068\n",
       " 1069\n",
       " 1070\n",
       " 1071\n",
       " 1072\n",
       " 1073\n",
       " 1074\n",
       " 1075\n",
       " 1076\n",
       " 1077\n",
       " 1078\n",
       " 1079\n",
       " 1080\n",
       " 1081\n",
       " 1082\n",
       " 1083\n",
       " 1084\n",
       " 1085\n",
       " 1086\n",
       " 1087\n",
       " 1088\n",
       " 1089\n",
       " 1090\n",
       " 1091\n",
       " 1092\n",
       "[torch.LongTensor of size 64]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T12:59:55.285437Z",
     "start_time": "2018-12-02T12:59:55.279049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.shape[1])==4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T10:26:34.454187Z",
     "start_time": "2018-12-02T10:26:34.448509Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.transpose(img[0].numpy(),[1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T10:27:05.547975Z",
     "start_time": "2018-12-02T10:27:05.344808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0c55da0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img[:,:,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T11:08:04.536065Z",
     "start_time": "2018-12-02T11:08:04.530129Z"
    }
   },
   "outputs": [],
   "source": [
    "img = img[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:15:52.780855Z",
     "start_time": "2018-12-02T09:15:52.659786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 96.40it/s]\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(os.listdir(input_dir))\n",
    "im_path, target_path, label = [], [], []\n",
    "for index,c in enumerate(tqdm(sorted(os.listdir(input_dir)))):\n",
    "    for obj in sorted(os.listdir(input_dir+'/'+c)):\n",
    "        ann, ext = os.path.splitext(obj)[0], os.path.splitext(obj)[1]\n",
    "        if ext not in ['.jpeg','.png']:\n",
    "            continue\n",
    "        im_path.append(os.path.join(input_dir,c,obj))\n",
    "        target_path.append(os.path.join(target_dir,c,obj))\n",
    "        label.append(int(ann))\n",
    "                \n",
    "images, targets, labels = np.array(im_path), np.array(target_path), np.array(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:16:05.629238Z",
     "start_time": "2018-12-02T09:16:05.619164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8058"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T11:48:54.112557Z",
     "start_time": "2018-12-02T11:48:53.707137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (conv9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (convtran1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv11): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (convtran2): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv13): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv14): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (convtran3): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv15): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (convtran4): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv17): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (conv19): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_nc, ngf=64, output_nc=3):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, ngf, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ngf, ngf, 3, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(ngf)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(ngf, ngf*2, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(ngf*2, ngf*2, 3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(ngf*2)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(ngf*2, ngf*4, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(ngf*4, ngf*4, 3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(ngf*4)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(ngf*4, ngf*8, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(ngf*8, ngf*8, 3, padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(ngf*8)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(ngf*8, ngf*8, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(ngf*8, ngf*8, 3, padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(ngf*8)\n",
    "\n",
    "        self.convtran1 = nn.ConvTranspose2d(ngf*8,ngf*8,2,stride=2)\n",
    "        \n",
    "        self.conv11 = nn.Conv2d(ngf*16,ngf*4,3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(ngf*4, ngf*4,3, padding=1)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(ngf*4)\n",
    "\n",
    "        self.convtran2 = nn.ConvTranspose2d(ngf*4,ngf*4,2,stride=2)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(ngf*8,ngf*2,3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(ngf*2,ngf*2,3, padding=1)\n",
    "        self.batchnorm7 = nn.BatchNorm2d(ngf*2)\n",
    "\n",
    "        self.convtran3 = nn.ConvTranspose2d(ngf*2,ngf*2,2,stride=2)\n",
    "\n",
    "        self.conv15 = nn.Conv2d(ngf*4,ngf,3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(ngf,ngf,3, padding=1)\n",
    "        self.batchnorm8 = nn.BatchNorm2d(ngf)\n",
    "\n",
    "        self.convtran4 = nn.ConvTranspose2d(ngf,ngf,2,stride=2)\n",
    "\n",
    "        self.conv17 = nn.Conv2d(ngf*2,ngf,3, padding=1)\n",
    "        self.conv18 = nn.Conv2d(ngf, ngf,3, padding=1)\n",
    "        self.batchnorm9 = nn.BatchNorm2d(ngf)\n",
    "              \n",
    "        self.conv19 = nn.Conv2d(ngf,output_nc,1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        c1 = torch.nn.functional.relu(self.batchnorm1(self.conv1(x)))\n",
    "        c1 = torch.nn.functional.relu(self.batchnorm1(self.conv2(c1)))\n",
    "        p1 = self.pool1(c1)\n",
    "        print('c1',c1.shape)\n",
    "        c2 = torch.nn.functional.relu(self.batchnorm2(self.conv3(p1)))\n",
    "        c2 = torch.nn.functional.relu(self.batchnorm2(self.conv4(c2)))\n",
    "        p2 = self.pool2(c2)\n",
    "        print('c2',c2.shape)\n",
    "        c3 = torch.nn.functional.relu(self.batchnorm3(self.conv5(p2)))\n",
    "        c3 = torch.nn.functional.relu(self.batchnorm3(self.conv6(c3)))\n",
    "        p3 = self.pool3(c3)\n",
    "        print('c3',c3.shape)\n",
    "        c4 = torch.nn.functional.relu(self.batchnorm4(self.conv7(p3)))\n",
    "        c4 = torch.nn.functional.relu(self.batchnorm4(self.conv8(c4)))\n",
    "        print('c4',c4.shape)\n",
    "        p4 = self.pool4(c4)\n",
    "\n",
    "        c5 = torch.nn.functional.relu(self.batchnorm5(self.conv9(p4)))\n",
    "        c5 = torch.nn.functional.relu(self.batchnorm5(self.conv10(c5)))\n",
    "        print('c5',c5.shape)\n",
    "        u6 = self.convtran1(c5)\n",
    "        u6 = torch.cat((u6,c4),dim=1)\n",
    "        print('u6',u6.shape)\n",
    "        c6 = torch.nn.functional.relu(self.batchnorm6(self.conv11(u6)))\n",
    "        c6 = torch.nn.functional.relu(self.batchnorm6(self.conv12(c6)))\n",
    "        print('c6',c6.shape)\n",
    "        u7 = self.convtran2(c6)\n",
    "        u7 = torch.cat((u7,c3),dim=1)\n",
    "        print('u7',u7.shape)\n",
    "        c7 = torch.nn.functional.relu(self.batchnorm7(self.conv13(u7)))\n",
    "        c7 = torch.nn.functional.relu(self.batchnorm7(self.conv14(c7)))\n",
    "        print('c7',c7.shape)\n",
    "        u8 = self.convtran3(c7)\n",
    "        u8 = torch.cat((u8,c2),dim=1)\n",
    "        print('u8',u8.shape)\n",
    "        c8 = torch.nn.functional.relu(self.batchnorm8(self.conv15(u8)))\n",
    "        c8 = torch.nn.functional.relu(self.batchnorm8(self.conv16(c8)))\n",
    "        print('c8',c8.shape)\n",
    "        u9 = self.convtran4(c8)\n",
    "        u9 = torch.cat((u9,c1),dim=1)\n",
    "        print('u9',u9.shape)\n",
    "        c9 = torch.nn.functional.relu(self.batchnorm9(self.conv17(u9)))\n",
    "        c9 = torch.nn.functional.relu(self.batchnorm9(self.conv18(c9)))\n",
    "        print('c9',c9.shape)\n",
    "        out = torch.nn.functional.sigmoid(self.conv19(c9))\n",
    "        \n",
    "        return out\n",
    "unet = UNet(3)\n",
    "unet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T11:48:54.735985Z",
     "start_time": "2018-12-02T11:48:54.671295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('c1', torch.Size([2, 64, 224, 224]))\n",
      "('c2', torch.Size([2, 128, 112, 112]))\n",
      "('c3', torch.Size([2, 256, 56, 56]))\n",
      "('c4', torch.Size([2, 512, 28, 28]))\n",
      "('c5', torch.Size([2, 512, 14, 14]))\n",
      "('u6', torch.Size([2, 1024, 28, 28]))\n",
      "('c6', torch.Size([2, 256, 28, 28]))\n",
      "('u7', torch.Size([2, 512, 56, 56]))\n",
      "('c7', torch.Size([2, 128, 56, 56]))\n",
      "('u8', torch.Size([2, 256, 112, 112]))\n",
      "('c8', torch.Size([2, 64, 112, 112]))\n",
      "('u9', torch.Size([2, 128, 224, 224]))\n",
      "('c9', torch.Size([2, 64, 224, 224]))\n"
     ]
    }
   ],
   "source": [
    "out = unet(Variable(torch.Tensor(img).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T11:13:57.972533Z",
     "start_time": "2018-12-02T11:13:57.962759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
